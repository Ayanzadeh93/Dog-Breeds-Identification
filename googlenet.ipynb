{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCEPTION_v3_starter.ipynb\n",
      "LICENSE\n",
      "README.md\n",
      "Res1211.ipynb\n",
      "Untitled.ipynb\n",
      "VGG19.ipynb\n",
      "custom_layers\n",
      "data_gen\n",
      "dens121.ipynb\n",
      "dense169.ipynb\n",
      "densenet121.py\n",
      "densenet161.py\n",
      "densenet169.py\n",
      "googlenet.ipynb\n",
      "googlenet.py\n",
      "imagenet_models\n",
      "inception_v3.py\n",
      "inception_v4.py\n",
      "inception_version4.ipynb\n",
      "keras_VGG19_without pretrain.ipynb\n",
      "labels.csv\n",
      "load_cifar10.py\n",
      "load_cifar10.pyc\n",
      "mixed.ipynb\n",
      "resnet101.ipynb\n",
      "resnet50.ipynb\n",
      "resnet_101.py\n",
      "resnet_152.py\n",
      "resnet_50.py\n",
      "result-2.csv\n",
      "result-3.csv\n",
      "result-4.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "vgg16.py\n",
      "vgg19.py\n",
      "view\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [01:41<00:00, 101.11it/s]\n",
      "100%|██████████| 10357/10357 [01:41<00:00, 102.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3)\n",
      "(10222, 120)\n",
      "(10357, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), name=\"conv1/7x7_s2\", activation=\"relu\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"valid\", strides=(2, 2), name=\"pool1/3x3_s2\", pool_size=(3, 3))`\n"
     ]
    },
    {
     "ename": "AsTensorError",
     "evalue": "('Cannot convert Tensor(\"pool1/3x3_s2/MaxPool:0\", shape=(?, 1, 56, 63), dtype=float32) to TensorType', <class 'tensorflow.python.framework.ops.Tensor'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAsTensorError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b56e466b106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# Load our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgooglenet_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# Start Fine-tuning.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-2b56e466b106>\u001b[0m in \u001b[0;36mgooglenet_model\u001b[1;34m(img_rows, img_cols, channel, num_classes)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mpool1_helper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoolHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1_zero_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mpool1_3x3_s2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool1/3x3_s2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool1_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mpool1_norm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool1/norm1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool1_3x3_s2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mconv2_3x3_reduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv2/3x3_reduce'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0002\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool1_norm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mconv2_3x3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv2/3x3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0002\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2_3x3_reduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/storage/aydin/kaggle-dog/Kaggle-dog-breeds-classification/cnn_finetune-master/custom_layers/googlenet_custom_layers.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mhalf_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;31m# half the local region\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0minput_sqr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# square the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mextra_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhalf_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# make an empty tensor with zero pads along channel dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0minput_sqr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_subtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_channels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalf_n\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhalf_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_sqr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set the center to be the squared input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \"\"\"\n\u001b[0;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_list'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'off'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[0musing\u001b[0m \u001b[0mDimShuffle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \"\"\"\n\u001b[1;32m--> 480\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         out_dtypes, out_broadcastables, inputs = self.get_output_info(\n\u001b[0;32m    482\u001b[0m             DimShuffle, *inputs)\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36mas_tensor_variable\u001b[1;34m(x, name, ndim)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mstr_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAsTensorError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot convert %s to TensorType\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;31m# this has a different name, because _as_tensor_variable is the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAsTensorError\u001b[0m: ('Cannot convert Tensor(\"pool1/3x3_s2/MaxPool:0\", shape=(?, 1, 56, 63), dtype=float32) to TensorType', <class 'tensorflow.python.framework.ops.Tensor'>)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.datasets import cifar10\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from custom_layers.googlenet_custom_layers import LRN, PoolHelper\n",
    "\n",
    "#from load_cifar10 import load_cifar10_data\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, merge, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from custom_layers.scale_layer import Scale\n",
    "\n",
    "from subprocess import check_output\n",
    "def googlenet_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    GoogLeNet a.k.a. Inception v1 for Keras\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/joelouismarino/a2ede9ab3928f999575423b9887abd14\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/open?id=0B319laiAPjU3RE1maU9MMlh2dnc\n",
    "    Blog Post: \n",
    "    http://joelouismarino.github.io/blog_posts/blog_googlenet_keras.html\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "    \n",
    "    input = Input(shape=(channel, img_rows, img_cols))\n",
    "    conv1_7x7_s2 = Convolution2D(64,7,7,subsample=(2,2),border_mode='same',activation='relu',name='conv1/7x7_s2',W_regularizer=l2(0.0002))(input)\n",
    "    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n",
    "    pool1_helper = PoolHelper()(conv1_zero_pad)\n",
    "    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool1/3x3_s2')(pool1_helper)\n",
    "    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n",
    "    conv2_3x3_reduce = Convolution2D(64,1,1,border_mode='same',activation='relu',name='conv2/3x3_reduce',W_regularizer=l2(0.0002))(pool1_norm1)\n",
    "    conv2_3x3 = Convolution2D(192,3,3,border_mode='same',activation='relu',name='conv2/3x3',W_regularizer=l2(0.0002))(conv2_3x3_reduce)\n",
    "    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n",
    "    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n",
    "    pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "    pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool2/3x3_s2')(pool2_helper)\n",
    "    \n",
    "    inception_3a_1x1 = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_3a/1x1',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_reduce = Convolution2D(96,1,1,border_mode='same',activation='relu',name='inception_3a/3x3_reduce',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3 = Convolution2D(128,3,3,border_mode='same',activation='relu',name='inception_3a/3x3',W_regularizer=l2(0.0002))(inception_3a_3x3_reduce)\n",
    "    inception_3a_5x5_reduce = Convolution2D(16,1,1,border_mode='same',activation='relu',name='inception_3a/5x5_reduce',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_5x5 = Convolution2D(32,5,5,border_mode='same',activation='relu',name='inception_3a/5x5',W_regularizer=l2(0.0002))(inception_3a_5x5_reduce)\n",
    "    inception_3a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_3a/pool')(pool2_3x3_s2)\n",
    "    inception_3a_pool_proj = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_3a/pool_proj',W_regularizer=l2(0.0002))(inception_3a_pool)\n",
    "    inception_3a_output = merge([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj],mode='concat',concat_axis=1,name='inception_3a/output')\n",
    "    \n",
    "    inception_3b_1x1 = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_3b/1x1',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_reduce = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_3b/3x3_reduce',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3 = Convolution2D(192,3,3,border_mode='same',activation='relu',name='inception_3b/3x3',W_regularizer=l2(0.0002))(inception_3b_3x3_reduce)\n",
    "    inception_3b_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_3b/5x5_reduce',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_5x5 = Convolution2D(96,5,5,border_mode='same',activation='relu',name='inception_3b/5x5',W_regularizer=l2(0.0002))(inception_3b_5x5_reduce)\n",
    "    inception_3b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_3b/pool')(inception_3a_output)\n",
    "    inception_3b_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_3b/pool_proj',W_regularizer=l2(0.0002))(inception_3b_pool)\n",
    "    inception_3b_output = merge([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj],mode='concat',concat_axis=1,name='inception_3b/output')\n",
    "    \n",
    "    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n",
    "    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool3/3x3_s2')(pool3_helper)\n",
    "    \n",
    "    inception_4a_1x1 = Convolution2D(192,1,1,border_mode='same',activation='relu',name='inception_4a/1x1',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_reduce = Convolution2D(96,1,1,border_mode='same',activation='relu',name='inception_4a/3x3_reduce',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3 = Convolution2D(208,3,3,border_mode='same',activation='relu',name='inception_4a/3x3',W_regularizer=l2(0.0002))(inception_4a_3x3_reduce)\n",
    "    inception_4a_5x5_reduce = Convolution2D(16,1,1,border_mode='same',activation='relu',name='inception_4a/5x5_reduce',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_5x5 = Convolution2D(48,5,5,border_mode='same',activation='relu',name='inception_4a/5x5',W_regularizer=l2(0.0002))(inception_4a_5x5_reduce)\n",
    "    inception_4a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4a/pool')(pool3_3x3_s2)\n",
    "    inception_4a_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4a/pool_proj',W_regularizer=l2(0.0002))(inception_4a_pool)\n",
    "    inception_4a_output = merge([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj],mode='concat',concat_axis=1,name='inception_4a/output')\n",
    "    \n",
    "    loss1_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss1/ave_pool')(inception_4a_output)\n",
    "    loss1_conv = Convolution2D(128,1,1,border_mode='same',activation='relu',name='loss1/conv',W_regularizer=l2(0.0002))(loss1_ave_pool)\n",
    "    loss1_flat = Flatten()(loss1_conv)\n",
    "    loss1_fc = Dense(1024,activation='relu',name='loss1/fc',W_regularizer=l2(0.0002))(loss1_flat)\n",
    "    loss1_drop_fc = Dropout(0.7)(loss1_fc)\n",
    "    loss1_classifier = Dense(1000,name='loss1/classifier',W_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n",
    "    \n",
    "    inception_4b_1x1 = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_4b/1x1',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_reduce = Convolution2D(112,1,1,border_mode='same',activation='relu',name='inception_4b/3x3_reduce',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3 = Convolution2D(224,3,3,border_mode='same',activation='relu',name='inception_4b/3x3',W_regularizer=l2(0.0002))(inception_4b_3x3_reduce)\n",
    "    inception_4b_5x5_reduce = Convolution2D(24,1,1,border_mode='same',activation='relu',name='inception_4b/5x5_reduce',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4b/5x5',W_regularizer=l2(0.0002))(inception_4b_5x5_reduce)\n",
    "    inception_4b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4b/pool')(inception_4a_output)\n",
    "    inception_4b_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4b/pool_proj',W_regularizer=l2(0.0002))(inception_4b_pool)\n",
    "    inception_4b_output = merge([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj],mode='concat',concat_axis=1,name='inception_4b_output')\n",
    "    \n",
    "    inception_4c_1x1 = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4c/1x1',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_reduce = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4c/3x3_reduce',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3 = Convolution2D(256,3,3,border_mode='same',activation='relu',name='inception_4c/3x3',W_regularizer=l2(0.0002))(inception_4c_3x3_reduce)\n",
    "    inception_4c_5x5_reduce = Convolution2D(24,1,1,border_mode='same',activation='relu',name='inception_4c/5x5_reduce',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4c/5x5',W_regularizer=l2(0.0002))(inception_4c_5x5_reduce)\n",
    "    inception_4c_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4c/pool')(inception_4b_output)\n",
    "    inception_4c_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4c/pool_proj',W_regularizer=l2(0.0002))(inception_4c_pool)\n",
    "    inception_4c_output = merge([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj],mode='concat',concat_axis=1,name='inception_4c/output')\n",
    "    \n",
    "    inception_4d_1x1 = Convolution2D(112,1,1,border_mode='same',activation='relu',name='inception_4d/1x1',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_reduce = Convolution2D(144,1,1,border_mode='same',activation='relu',name='inception_4d/3x3_reduce',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3 = Convolution2D(288,3,3,border_mode='same',activation='relu',name='inception_4d/3x3',W_regularizer=l2(0.0002))(inception_4d_3x3_reduce)\n",
    "    inception_4d_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_4d/5x5_reduce',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4d/5x5',W_regularizer=l2(0.0002))(inception_4d_5x5_reduce)\n",
    "    inception_4d_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4d/pool')(inception_4c_output)\n",
    "    inception_4d_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4d/pool_proj',W_regularizer=l2(0.0002))(inception_4d_pool)\n",
    "    inception_4d_output = merge([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj],mode='concat',concat_axis=1,name='inception_4d/output')\n",
    "    \n",
    "    loss2_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss2/ave_pool')(inception_4d_output)\n",
    "    loss2_conv = Convolution2D(128,1,1,border_mode='same',activation='relu',name='loss2/conv',W_regularizer=l2(0.0002))(loss2_ave_pool)\n",
    "    loss2_flat = Flatten()(loss2_conv)\n",
    "    loss2_fc = Dense(1024,activation='relu',name='loss2/fc',W_regularizer=l2(0.0002))(loss2_flat)\n",
    "    loss2_drop_fc = Dropout(0.7)(loss2_fc)\n",
    "    loss2_classifier = Dense(1000,name='loss2/classifier',W_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n",
    "    \n",
    "    inception_4e_1x1 = Convolution2D(256,1,1,border_mode='same',activation='relu',name='inception_4e/1x1',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_reduce = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_4e/3x3_reduce',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3 = Convolution2D(320,3,3,border_mode='same',activation='relu',name='inception_4e/3x3',W_regularizer=l2(0.0002))(inception_4e_3x3_reduce)\n",
    "    inception_4e_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_4e/5x5_reduce',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_4e/5x5',W_regularizer=l2(0.0002))(inception_4e_5x5_reduce)\n",
    "    inception_4e_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4e/pool')(inception_4d_output)\n",
    "    inception_4e_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4e/pool_proj',W_regularizer=l2(0.0002))(inception_4e_pool)\n",
    "    inception_4e_output = merge([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj],mode='concat',concat_axis=1,name='inception_4e/output')\n",
    "    \n",
    "    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n",
    "    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool4/3x3_s2')(pool4_helper)\n",
    "    \n",
    "    inception_5a_1x1 = Convolution2D(256,1,1,border_mode='same',activation='relu',name='inception_5a/1x1',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_reduce = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_5a/3x3_reduce',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3 = Convolution2D(320,3,3,border_mode='same',activation='relu',name='inception_5a/3x3',W_regularizer=l2(0.0002))(inception_5a_3x3_reduce)\n",
    "    inception_5a_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_5a/5x5_reduce',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_5a/5x5',W_regularizer=l2(0.0002))(inception_5a_5x5_reduce)\n",
    "    inception_5a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_5a/pool')(pool4_3x3_s2)\n",
    "    inception_5a_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_5a/pool_proj',W_regularizer=l2(0.0002))(inception_5a_pool)\n",
    "    inception_5a_output = merge([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj],mode='concat',concat_axis=1,name='inception_5a/output')\n",
    "    \n",
    "    inception_5b_1x1 = Convolution2D(384,1,1,border_mode='same',activation='relu',name='inception_5b/1x1',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_reduce = Convolution2D(192,1,1,border_mode='same',activation='relu',name='inception_5b/3x3_reduce',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3 = Convolution2D(384,3,3,border_mode='same',activation='relu',name='inception_5b/3x3',W_regularizer=l2(0.0002))(inception_5b_3x3_reduce)\n",
    "    inception_5b_5x5_reduce = Convolution2D(48,1,1,border_mode='same',activation='relu',name='inception_5b/5x5_reduce',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_5b/5x5',W_regularizer=l2(0.0002))(inception_5b_5x5_reduce)\n",
    "    inception_5b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_5b/pool')(inception_5a_output)\n",
    "    inception_5b_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_5b/pool_proj',W_regularizer=l2(0.0002))(inception_5b_pool)\n",
    "    inception_5b_output = merge([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj],mode='concat',concat_axis=1,name='inception_5b/output')\n",
    "    \n",
    "    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7),strides=(1,1),name='pool5/7x7_s2')(inception_5b_output)\n",
    "    loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "    pool5_drop_7x7_s1 = Dropout(0.4)(loss3_flat)\n",
    "    loss3_classifier = Dense(1000,name='loss3/classifier',W_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act = Activation('softmax',name='prob')(loss3_classifier)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(input=input, output=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n",
    "    \n",
    "    # Load ImageNet pre-trained data \n",
    "    model.load_weights('imagenet_models/googlenet_weights.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    loss3_classifier_statefarm = Dense(num_classes,name='loss3/classifier',W_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act_statefarm = Activation('softmax',name='prob')(loss3_classifier_statefarm)\n",
    "    loss2_classifier_statefarm = Dense(num_classes,name='loss2/classifier',W_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act_statefarm = Activation('softmax')(loss2_classifier_statefarm)\n",
    "    loss1_classifier_statefarm = Dense(num_classes,name='loss1/classifier',W_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act_statefarm = Activation('softmax')(loss1_classifier_statefarm)\n",
    "\n",
    "    # Create another model with our customized softmax\n",
    "    model = Model(input=input, output=[loss1_classifier_act_statefarm,loss2_classifier_act_statefarm,loss3_classifier_act_statefarm])\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 120 \n",
    "    batch_size = 16 \n",
    "    nb_epoch = 10\n",
    "    \n",
    "    directory_path = \"/home/aydin/storage/aydin/kaggle-dog/Kaggle-dog-breeds-classification/cnn_finetune-master/\"\n",
    "\n",
    "    print(check_output([\"ls\", directory_path]).decode(\"utf8\"))\n",
    "\n",
    "    df_train = pd.read_csv(directory_path+'labels.csv')\n",
    "    df_test = pd.read_csv(directory_path+'sample_submission.csv')\n",
    "\n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "\n",
    "    im_size = 224\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "  \n",
    "\n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread(directory_path+'train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    for f in tqdm(df_test['id'].values):\n",
    "        img = cv2.imread(directory_path+'test/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "\n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    x_test  = np.array(x_test, np.float32) / 255.\n",
    "\n",
    "    print(x_train_raw.shape)\n",
    "    print(y_train_raw.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.1, random_state=1)\n",
    "\n",
    "    # Load our model\n",
    "    model = googlenet_model(img_rows, img_cols, channel, num_classes)\n",
    "\n",
    "    # Start Fine-tuning. \n",
    "    # Notice that googlenet takes 3 sets of labels for outputs, one for each auxillary classifier\n",
    "    model.fit(X_train, [Y_train, Y_train, Y_train],\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, [Y_valid, Y_valid, Y_valid]),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Combine 3 set of outputs using averaging\n",
    "    predictions_valid = sum(predictions_valid)/len(predictions_valid)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "    score = log_loss(Y_valid, predictions_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
