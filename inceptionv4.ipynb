{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aydin/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_layers\n",
      "densenet121.py\n",
      "densenet161.py\n",
      "densenet169.py\n",
      "googlenet.py\n",
      "imagenet_models\n",
      "inception_v3.py\n",
      "inceptionv4.ipynb\n",
      "inception_v4.py\n",
      "labels.csv\n",
      "LICENSE\n",
      "load_cifar10.py\n",
      "__pycache__\n",
      "README.md\n",
      "Res1211.ipynb\n",
      "resnet_101.py\n",
      "resnet_152.py\n",
      "resnet_50.py\n",
      "result-2.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "vgg16.py\n",
      "vgg19.py\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:36<00:00, 281.79it/s]\n",
      "100%|██████████| 10357/10357 [00:36<00:00, 286.24it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b21ed05a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0my_train_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mx_train_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mx_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from custom_layers.scale_layer import Scale\n",
    "#from load_cifar10 import load_cifar10_data\n",
    "from subprocess import check_output\n",
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1), bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "    \"\"\"\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      border_mode=border_mode,\n",
    "                      bias=bias)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def block_inception_a(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), border_mode='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "\n",
    "    x = merge([branch_0, branch_1, branch_2, branch_3], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3,3), strides=(2,2), border_mode='valid')(input)\n",
    "\n",
    "    x = merge([branch_0, branch_1, branch_2], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), border_mode='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "\n",
    "    x = merge([branch_0, branch_1, branch_2, branch_3], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), border_mode='valid')(input)\n",
    "\n",
    "    x = merge([branch_0, branch_1, branch_2], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = merge([branch_10, branch_11], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = merge([branch_20, branch_21], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = merge([branch_0, branch_1, branch_2, branch_3], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inception_v4_base(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, border_mode='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), border_mode='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "\n",
    "    net = merge([branch_0, branch_1], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, border_mode='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, border_mode='valid')\n",
    "\n",
    "    net = merge([branch_0, branch_1], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, subsample=(2,2), border_mode='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), border_mode='valid')(net)\n",
    "\n",
    "    net = merge([branch_0, branch_1], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "      net = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "      net = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "      net = block_inception_c(net)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v4_model(img_rows, img_cols, color_type=1, num_classeses=None, dropout_keep_prob=0.2):\n",
    "    '''\n",
    "    Inception V4 Model for Keras\n",
    "    Model Schema is based on\n",
    "    https://github.com/kentsommer/keras-inceptionV4\n",
    "    ImageNet Pretrained Weights \n",
    "    Theano: https://github.com/kentsommer/keras-inceptionV4/releases/download/2.0/inception-v4_weights_th_dim_ordering_th_kernels.h5\n",
    "    TensorFlow: https://github.com/kentsommer/keras-inceptionV4/releases/download/2.0/inception-v4_weights_tf_dim_ordering_tf_kernels.h5\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    '''\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        inputs = Input((3, 299, 299))\n",
    "    else:\n",
    "        inputs = Input((299, 299, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    net = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    net_old = AveragePooling2D((8,8), border_mode='valid')(net)\n",
    "\n",
    "    # 1 x 1 x 1536\n",
    "    net_old = Dropout(dropout_keep_prob)(net_old)\n",
    "    net_old = Flatten()(net_old)\n",
    "\n",
    "    # 1536\n",
    "    predictions = Dense(output_dim=1001, activation='softmax')(net_old)\n",
    "\n",
    "    model = Model(inputs, predictions, name='inception_v4')\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "      # Use pre-trained weights for Theano backend\n",
    "      weights_path = 'imagenet_models/inception-v4_weights_th_dim_ordering_th_kernels.h5'\n",
    "    else:\n",
    "      # Use pre-trained weights for Tensorflow backend\n",
    "      weights_path = 'imagenet_models/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    \n",
    "    \n",
    "    # Freeze layers. This will only update weights for last 6 layers\n",
    "    for layer in model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    net_ft = AveragePooling2D((8,8), border_mode='valid')(net)\n",
    "    net_ft = Dropout(dropout_keep_prob)(net_ft)\n",
    "    net_ft = Flatten()(net_ft)\n",
    "    predictions_ft = Dense(output_dim=num_classes, activation='softmax')(net_ft)\n",
    "\n",
    "    model = Model(inputs, predictions_ft, name='inception_v4')\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 299, 299 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 120\n",
    "    batch_size = 8 \n",
    "    nb_epoch = 10\n",
    "    directory_path = \"/home/aydin/Documents/Kaggle/cnn_finetune-master/\"\n",
    "\n",
    "    print(check_output([\"ls\", directory_path]).decode(\"utf8\"))\n",
    "\n",
    "    df_train = pd.read_csv(directory_path+'labels.csv')\n",
    "    df_test = pd.read_csv(directory_path+'sample_submission.csv')\n",
    "\n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "\n",
    "    im_size = 299\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "\n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread(directory_path+'train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    for f in tqdm(df_test['id'].values):\n",
    "        img = cv2.imread(directory_path+'test/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "\n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    x_test  = np.array(x_test, np.float32) / 255.\n",
    "\n",
    "    print(x_train_raw.shape)\n",
    "    print(y_train_raw.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    num_class = y_train_raw.shape[1]\n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, Y_train, X_valid, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Load our model\n",
    "    model = inception_v4_model(img_rows, img_cols, channel, num_classes, dropout_keep_prob=0.2)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "score = log_loss(Y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aydin/Documents/Kaggle/cnn_finetune-master'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
